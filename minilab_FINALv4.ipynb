{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESUBMISSION SUMMARY OF CHANGES\n",
    "\n",
    "## Added much more code/ouput/discussion in the Create Models section to include parameters changes to improve model accuracy for both SVM with SGD and logistic regression models. Changed the SVM print so you could see the accuracies for each fold.\n",
    "\n",
    "## Added more discussion in the Interpret Feature Importance Section.\n",
    "\n",
    "## Noticed that one of your comments was that you were seeeing only 3 CV outputs even though are code says 5. Not sure how, but we are seeing 5 when we run the output.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 7331 Data Mining\n",
    "## Mini Lab\n",
    "## 2/17/2019\n",
    "## Mallory Hightower, Richard Farrow, and Brandon de la Houssaye\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      Name Sex   Age  Height  Weight            Team  \\\n",
       "0   1                 A Dijiang   M  24.0   180.0    80.0           China   \n",
       "1   2                  A Lamusi   M  23.0   170.0    60.0           China   \n",
       "2   3       Gunnar Nielsen Aaby   M  24.0     NaN     NaN         Denmark   \n",
       "3   4      Edgar Lindenau Aabye   M  34.0     NaN     NaN  Denmark/Sweden   \n",
       "4   5  Christine Jacoba Aaftink   F  21.0   185.0    82.0     Netherlands   \n",
       "\n",
       "   NOC        Games  Year  Season       City          Sport  \\\n",
       "0  CHN  1992 Summer  1992  Summer  Barcelona     Basketball   \n",
       "1  CHN  2012 Summer  2012  Summer     London           Judo   \n",
       "2  DEN  1920 Summer  1920  Summer  Antwerpen       Football   \n",
       "3  DEN  1900 Summer  1900  Summer      Paris     Tug-Of-War   \n",
       "4  NED  1988 Winter  1988  Winter    Calgary  Speed Skating   \n",
       "\n",
       "                              Event Medal  \n",
       "0       Basketball Men's Basketball   NaN  \n",
       "1      Judo Men's Extra-Lightweight   NaN  \n",
       "2           Football Men's Football   NaN  \n",
       "3       Tug-Of-War Men's Tug-Of-War  Gold  \n",
       "4  Speed Skating Women's 500 metres   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import and view the data\n",
    "df_no_edit = pd.read_csv (\"C:/Users/brndn/OneDrive/Documents/Semester 3 Courses/Data Mining/Group Project/OlympicData/Data/Olympicdata.csv\")\n",
    "df_no_edit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the orginal, un-edited data set before making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Year</th>\n",
       "      <th>IsMedal</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>IsSummer</th>\n",
       "      <th>NOC_AFG</th>\n",
       "      <th>NOC_AHO</th>\n",
       "      <th>NOC_ALB</th>\n",
       "      <th>...</th>\n",
       "      <th>Sport_Table Tennis</th>\n",
       "      <th>Sport_Taekwondo</th>\n",
       "      <th>Sport_Tennis</th>\n",
       "      <th>Sport_Trampolining</th>\n",
       "      <th>Sport_Triathlon</th>\n",
       "      <th>Sport_Tug-Of-War</th>\n",
       "      <th>Sport_Volleyball</th>\n",
       "      <th>Sport_Water Polo</th>\n",
       "      <th>Sport_Weightlifting</th>\n",
       "      <th>Sport_Wrestling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1992</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>175.33897</td>\n",
       "      <td>70.702393</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>175.33897</td>\n",
       "      <td>70.702393</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>185.00000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Height     Weight  Year  IsMedal  IsMale  IsSummer  NOC_AFG  \\\n",
       "0  24.0  180.00000  80.000000  1992        0       1         1        0   \n",
       "1  23.0  170.00000  60.000000  2012        0       1         1        0   \n",
       "2  24.0  175.33897  70.702393  1920        0       1         1        0   \n",
       "3  34.0  175.33897  70.702393  1900        1       1         1        0   \n",
       "4  21.0  185.00000  82.000000  1988        0       0         0        0   \n",
       "\n",
       "   NOC_AHO  NOC_ALB       ...         Sport_Table Tennis  Sport_Taekwondo  \\\n",
       "0        0        0       ...                          0                0   \n",
       "1        0        0       ...                          0                0   \n",
       "2        0        0       ...                          0                0   \n",
       "3        0        0       ...                          0                0   \n",
       "4        0        0       ...                          0                0   \n",
       "\n",
       "   Sport_Tennis  Sport_Trampolining  Sport_Triathlon  Sport_Tug-Of-War  \\\n",
       "0             0                   0                0                 0   \n",
       "1             0                   0                0                 0   \n",
       "2             0                   0                0                 0   \n",
       "3             0                   0                0                 1   \n",
       "4             0                   0                0                 0   \n",
       "\n",
       "   Sport_Volleyball  Sport_Water Polo  Sport_Weightlifting  Sport_Wrestling  \n",
       "0                 0                 0                    0                0  \n",
       "1                 0                 0                    0                0  \n",
       "2                 0                 0                    0                0  \n",
       "3                 0                 0                    0                0  \n",
       "4                 0                 0                    0                0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make all the edits to the data before using it\n",
    "\n",
    "#drop the ID, Team, Name, Games, City and Event columns\n",
    "# Games  is being dropped becuase year and season already contain that value\n",
    "# Event is esentially a more specific sport, which we most likely will not need and will reduce later one-hot encoding\n",
    "# City is also a little more granular and dropping it reduced later one-hot ecoding and processing speeds\n",
    "df1 = df_no_edit.drop(['ID'], axis=1)\n",
    "df1 = df1.drop(['Team'], axis=1)\n",
    "df1 = df1.drop(['Event'], axis=1)\n",
    "df1 = df1.drop(['Name'], axis=1)\n",
    "df1 = df1.drop(['Games'], axis=1)\n",
    "df1 = df1.drop(['City'], axis=1)\n",
    "\n",
    "#impute Age, Height, Weight, and Medal\n",
    "#replace NaN with mean of column\n",
    "df1['Weight']=df1['Weight'].fillna(df1['Weight'].mean())\n",
    "df1['Height']=df1['Height'].fillna(df1['Height'].mean())\n",
    "df1['Age']=df1['Age'].fillna(df1['Age'].mean())\n",
    "\n",
    "#replace the NaN in medal to \"None\"\n",
    "df1[\"Medal\"].fillna(\"None\", inplace = True)\n",
    "\n",
    "#replace the different medal categories to \"Medal\" to make it a binary classification\n",
    "df1['Medal']= df1['Medal'].replace('Gold', 'Medal')\n",
    "df1['Medal']= df1['Medal'].replace('Silver', 'Medal')\n",
    "df1['Medal']= df1['Medal'].replace('Bronze', 'Medal')\n",
    "\n",
    "df1 ['IsMedal'] =df1.Medal == 'Medal'\n",
    "df1.IsMedal = df1.IsMedal.astype(np.int)\n",
    "df1 = df1.drop(['Medal'], axis=1)\n",
    "\n",
    "\n",
    "# replace the current Sex atribute with IsMale to avoid one hot encoding\n",
    "#delete Sex attribute afterwards\n",
    "df1['IsMale'] = df1.Sex=='M'\n",
    "df1.IsMale = df1.IsMale.astype(np.int)\n",
    "df1 = df1.drop(['Sex'], axis=1)\n",
    "\n",
    "# replace current Season attribute with IsSummer to avoid one hot encoding\n",
    "df1['IsSummer'] = df1.Season=='Summer'\n",
    "df1.IsSummer = df1.IsSummer.astype(np.int)\n",
    "df1 = df1.drop(['Season'], axis=1)\n",
    "\n",
    "df=pd.get_dummies(df1, columns=['NOC', 'Sport'])\n",
    "\n",
    "if 'NOC' in df:   \n",
    "    del df['NOC']    \n",
    "if 'Sport' in df:\n",
    "    del df['Sport'] \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=5, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'IsMedal' in df:\n",
    "    y = df['IsMedal'].values # get the labels we want  \n",
    "    X = df.loc[:, df.columns != 'IsMedal'].values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 5\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Year</th>\n",
       "      <th>IsMedal</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>IsSummer</th>\n",
       "      <th>NOC_AFG</th>\n",
       "      <th>NOC_AHO</th>\n",
       "      <th>NOC_ALB</th>\n",
       "      <th>...</th>\n",
       "      <th>Sport_Table Tennis</th>\n",
       "      <th>Sport_Taekwondo</th>\n",
       "      <th>Sport_Tennis</th>\n",
       "      <th>Sport_Trampolining</th>\n",
       "      <th>Sport_Triathlon</th>\n",
       "      <th>Sport_Tug-Of-War</th>\n",
       "      <th>Sport_Volleyball</th>\n",
       "      <th>Sport_Water Polo</th>\n",
       "      <th>Sport_Weightlifting</th>\n",
       "      <th>Sport_Wrestling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.00000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.556898</td>\n",
       "      <td>175.33897</td>\n",
       "      <td>70.702393</td>\n",
       "      <td>1978.378480</td>\n",
       "      <td>0.146738</td>\n",
       "      <td>0.725129</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.026387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.280857</td>\n",
       "      <td>9.27810</td>\n",
       "      <td>12.574690</td>\n",
       "      <td>29.877632</td>\n",
       "      <td>0.353845</td>\n",
       "      <td>0.446450</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.016066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084611</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.102201</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.044129</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>0.111346</td>\n",
       "      <td>0.118257</td>\n",
       "      <td>0.119627</td>\n",
       "      <td>0.160284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>127.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1896.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>175.33897</td>\n",
       "      <td>70.702393</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>226.00000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age        Height         Weight           Year  \\\n",
       "count  271116.000000  271116.00000  271116.000000  271116.000000   \n",
       "mean       25.556898     175.33897      70.702393    1978.378480   \n",
       "std         6.280857       9.27810      12.574690      29.877632   \n",
       "min        10.000000     127.00000      25.000000    1896.000000   \n",
       "25%        22.000000     170.00000      63.000000    1960.000000   \n",
       "50%        25.000000     175.33897      70.702393    1988.000000   \n",
       "75%        28.000000     180.00000      75.000000    2002.000000   \n",
       "max        97.000000     226.00000     214.000000    2016.000000   \n",
       "\n",
       "             IsMedal         IsMale       IsSummer        NOC_AFG  \\\n",
       "count  271116.000000  271116.000000  271116.000000  271116.000000   \n",
       "mean        0.146738       0.725129       0.820874       0.000465   \n",
       "std         0.353845       0.446450       0.383459       0.021553   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       0.000000   \n",
       "50%         0.000000       1.000000       1.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             NOC_AHO        NOC_ALB       ...         Sport_Table Tennis  \\\n",
       "count  271116.000000  271116.000000       ...              271116.000000   \n",
       "mean        0.000291       0.000258       ...                   0.007211   \n",
       "std         0.017068       0.016066       ...                   0.084611   \n",
       "min         0.000000       0.000000       ...                   0.000000   \n",
       "25%         0.000000       0.000000       ...                   0.000000   \n",
       "50%         0.000000       0.000000       ...                   0.000000   \n",
       "75%         0.000000       0.000000       ...                   0.000000   \n",
       "max         1.000000       1.000000       ...                   1.000000   \n",
       "\n",
       "       Sport_Taekwondo   Sport_Tennis  Sport_Trampolining  Sport_Triathlon  \\\n",
       "count    271116.000000  271116.000000       271116.000000    271116.000000   \n",
       "mean          0.002235       0.010556            0.000561         0.001951   \n",
       "std           0.047225       0.102201            0.023671         0.044129   \n",
       "min           0.000000       0.000000            0.000000         0.000000   \n",
       "25%           0.000000       0.000000            0.000000         0.000000   \n",
       "50%           0.000000       0.000000            0.000000         0.000000   \n",
       "75%           0.000000       0.000000            0.000000         0.000000   \n",
       "max           1.000000       1.000000            1.000000         1.000000   \n",
       "\n",
       "       Sport_Tug-Of-War  Sport_Volleyball  Sport_Water Polo  \\\n",
       "count     271116.000000     271116.000000     271116.000000   \n",
       "mean           0.000627          0.012556          0.014186   \n",
       "std            0.025033          0.111346          0.118257   \n",
       "min            0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000   \n",
       "50%            0.000000          0.000000          0.000000   \n",
       "75%            0.000000          0.000000          0.000000   \n",
       "max            1.000000          1.000000          1.000000   \n",
       "\n",
       "       Sport_Weightlifting  Sport_Wrestling  \n",
       "count        271116.000000    271116.000000  \n",
       "mean              0.014521         0.026387  \n",
       "std               0.119627         0.160284  \n",
       "min               0.000000         0.000000  \n",
       "25%               0.000000         0.000000  \n",
       "50%               0.000000         0.000000  \n",
       "75%               0.000000         0.000000  \n",
       "max               1.000000         1.000000  \n",
       "\n",
       "[8 rows x 303 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGINNING OF CHANGED CODE ON THE CREATE MODELS SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "#### This section has new code and output discussion to provide insight into changing the model parameters to increase model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGINNING OF CHANGED CODE ON THE CREATE MODELS SECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.8542158453821186\n",
      "confusion matrix\n",
      " [[45976   257]\n",
      " [ 7648   343]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.8569637061079964\n",
      "confusion matrix\n",
      " [[45939   347]\n",
      " [ 7409   529]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.8574063145470641\n",
      "confusion matrix\n",
      " [[45941   427]\n",
      " [ 7305   551]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.8556358807907938\n",
      "confusion matrix\n",
      " [[45813   374]\n",
      " [ 7454   583]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.8547875479492476\n",
      "confusion matrix\n",
      " [[46008   209]\n",
      " [ 7665   342]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.3, class_weight=None) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the logistic regression modle with these parameters: (penalty='l2', C=0.3, class_weight=None). Seeing an accuracy of about 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.8580517851873709\n",
      "confusion matrix\n",
      " [[45982   348]\n",
      " [ 7349   545]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.857904249041015\n",
      "confusion matrix\n",
      " [[45939   327]\n",
      " [ 7378   580]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.8584943936264384\n",
      "confusion matrix\n",
      " [[45972   367]\n",
      " [ 7306   579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.8562813514311006\n",
      "confusion matrix\n",
      " [[45857   352]\n",
      " [ 7441   574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.8585497196813219\n",
      "confusion matrix\n",
      " [[45986   356]\n",
      " [ 7314   568]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# penalty was changed to l1. \n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.3, class_weight=None) \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran logistic regression again using the same cross validation and changed the penalty to l1 (previously it was l2). The penalty has to do with how the model handles overfitting the data. We do not want an overfitted model! Lasso regression uses l1 as the penalty whereas ridge regression uses l2. Lasso (l1) is useful for datasets with many attributes because it shrinks the less important attribute coefficients to 0 and works as a type of feature selection. We found that running the logistic regression with an l1 penalty dramatically increased the time to run the model but did not produce higher model accuracies. The accuracies for each iteration were all about 0.85-0.86 (as shown above in the ouput). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.8552670404249041\n",
      "confusion matrix\n",
      " [[46246    52]\n",
      " [ 7796   130]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.8579226910593095\n",
      "confusion matrix\n",
      " [[46256    99]\n",
      " [ 7605   264]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.8573878725287696\n",
      "confusion matrix\n",
      " [[46267   112]\n",
      " [ 7621   224]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.8515048686928297\n",
      "confusion matrix\n",
      " [[46023    55]\n",
      " [ 7997   149]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.8534228385954559\n",
      "confusion matrix\n",
      " [[46124    61]\n",
      " [ 7887   152]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# penalty was changed back to l2\n",
    "# decease C (more regularization)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.005, class_weight=None) \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we decided to use the l2 penalty over the l1 penalty due to the much longer time to run the l1 penalty with no significant change in model accruacy, we ran logistic regression again using the same cross validation and changed the C to 0.005 (previously it was 0.3). C is the inverse of the regularization strength (lambda) and therefore smaller values mean stronger regularization. Regularization is a way of applying a penalty to the model in order to reduce overfitting. If we really want to reduce overfitting, we would use a very small C to achieve a higher regularization penalty. \n",
    "\n",
    "After reducing C to 0.005 (much higher regularization penalty), there were no significant changes in model accuracy. The CV fold accuracies are all about 0.85. However, it does seem that a smaller C decreases the accuracy by about 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.8562260253762172\n",
      "confusion matrix\n",
      " [[45882   393]\n",
      " [ 7403   546]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.8534781646503393\n",
      "confusion matrix\n",
      " [[45874   296]\n",
      " [ 7649   405]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.8566501917969903\n",
      "confusion matrix\n",
      " [[45982   344]\n",
      " [ 7429   469]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.8548428740041311\n",
      "confusion matrix\n",
      " [[45965   258]\n",
      " [ 7613   388]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.8569268220714075\n",
      "confusion matrix\n",
      " [[45948   339]\n",
      " [ 7419   518]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# increase C (less regularization)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.5, class_weight=None) \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we tried decreasing C to 0.005 to use a higher regularization penalty on the model, we increased C to 1.5. We wanted to see how well the model would do with a smaller regularization penalty. Increasing C means we may have an overfitted model. \n",
    "\n",
    "With a higher C=1.5, the CV fold accuracies are still around 0.85. No significant changes in accuracy by increasing C to 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.8548613160224255\n",
      "confusion matrix\n",
      " [[45876   347]\n",
      " [ 7523   478]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.8541605193272351\n",
      "confusion matrix\n",
      " [[45871   332]\n",
      " [ 7576   445]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.8574985246385365\n",
      "confusion matrix\n",
      " [[45950   299]\n",
      " [ 7428   547]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.8578304809678371\n",
      "confusion matrix\n",
      " [[45897   440]\n",
      " [ 7269   618]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.8540683092357627\n",
      "confusion matrix\n",
      " [[45850   239]\n",
      " [ 7674   461]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# increase C to a much higher number (less regularization)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=20, class_weight=None) \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to see what happens, we increased C to a very large number: 20. This essentially tells the model to have a very low penalty for overfitting. We were curious to see if we could achieve any higher accuracies, even at the risk of overfitting. \n",
    "\n",
    "It looks like even though we really increased C, the accuracy of the models only inceased by about 0.001. It is not worth it to risk overfitting the model for such a small increase in accuracy. We will resort to using the middle grounnd regularization penalty of 0.3 (the defualt is 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.6728385954558866\n",
      "confusion matrix\n",
      " [[31064 15287]\n",
      " [ 2453  5420]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.6758446444378873\n",
      "confusion matrix\n",
      " [[31298 15075]\n",
      " [ 2502  5349]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.6731889938034818\n",
      "confusion matrix\n",
      " [[31013 15199]\n",
      " [ 2522  5490]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.6764901150781941\n",
      "confusion matrix\n",
      " [[31207 15064]\n",
      " [ 2478  5475]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.6743139569194453\n",
      "confusion matrix\n",
      " [[31025 15328]\n",
      " [ 2332  5539]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# change to class_weight=balanced (vs None)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.3, class_weight='balanced') \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We decided that a C of 0.3 was a good regularization penalty constant (good accuracies and lower risk of overfitting the model) and next decided to experiment with the class_weight parameter. The class_weight parameter deals with the weighting of the classes to help achieve a more equal balance and representation of classes in the model. We have been using the default of class_weight=None, but here we use class_weight=balance. Using class_weight=balance will increase the weight of our minority class (IsMedal=0). Balancing the classes in the logistic regression may help achieve higher accuracy in very unbalanced datasets like ours.\n",
    "\n",
    "Changing the class_weight to balanced resulted in the the largest change in our model accuracies. This parameter change dropped the accuracy from 0.85 to around 0.67. This change makes sense because with a very unbalanced dataset like ours, the model could just be predicting the majority class all the time and getting a high accuracy. This is NOT a good model and an example of why you cannot soley rely on accuracy as the primary model metric. We will look at the confusion matrices to see a better understanding of the model results. \n",
    "\n",
    "From the confusion matrices, it looks like there are about 30,980 true positives, about 15,100-15,300 false positives, about 2,450 false negatives, and about 5,500 true negatives. This is very interesting. Compared to the same model with l2 and C=0.3 but with class_weight=None, there are about 15,000 less tbv,.8rue positives, 15,000 more false positives, 5,000 less false negatives, and about 5,000 more true negatives. We want the numbers on the left to right diagonal to be higher (more true positives and true negatives) and to minimize the false results on the right to left diagonal. Because of this, we will use the class_weight=balanced parameter to adjust for our highly inbalanced classes, even though our accruacy decreases. This technique avoids using a model that just predicts the majority class.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.6754942460902921\n",
      "confusion matrix\n",
      " [[31061 15141]\n",
      " [ 2455  5567]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.6728017114192977\n",
      "confusion matrix\n",
      " [[31032 15279]\n",
      " [ 2463  5450]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.6707362053703158\n",
      "confusion matrix\n",
      " [[30775 15464]\n",
      " [ 2390  5595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.6769142814989673\n",
      "confusion matrix\n",
      " [[31110 15032]\n",
      " [ 2487  5595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.6695190321628799\n",
      "confusion matrix\n",
      " [[30815 15559]\n",
      " [ 2361  5489]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# increase C (less regularization)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=20, class_weight='balanced') \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used class_weight=balanced and increased C to 20. We do not see any significant changes in the accuracy or the confusion matrices with a lower regularization penalty (higher C value). The accuracy is still around 0.67."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.5371237828267925\n",
      "confusion matrix\n",
      " [[24234 22023]\n",
      " [ 3076  4891]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.5366627323694305\n",
      "confusion matrix\n",
      " [[24227 22093]\n",
      " [ 3031  4873]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.5355008852168781\n",
      "confusion matrix\n",
      " [[24219 22149]\n",
      " [ 3038  4818]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.5385622602537622\n",
      "confusion matrix\n",
      " [[24228 21879]\n",
      " [ 3142  4975]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.5347263204485099\n",
      "confusion matrix\n",
      " [[24067 22160]\n",
      " [ 3069  4928]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# decrease C by a lot! (more regularization)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.00001, class_weight='balanced') \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that significantly decreasing C actually decreased the accruacy to 0.54 and increased the number of false positives. Not good for the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.6784080849808203\n",
      "confusion matrix\n",
      " [[31522 14894]\n",
      " [ 2544  5264]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.6766929772794334\n",
      "confusion matrix\n",
      " [[31372 14830]\n",
      " [ 2701  5321]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.6832583357922691\n",
      "confusion matrix\n",
      " [[31719 14508]\n",
      " [ 2667  5330]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.6825022130421954\n",
      "confusion matrix\n",
      " [[31667 14546]\n",
      " [ 2670  5341]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.6834611979935085\n",
      "confusion matrix\n",
      " [[31687 14548]\n",
      " [ 2616  5373]]\n"
     ]
    }
   ],
   "source": [
    "# use the same set up as used previously, just change the parameters to make the model more accurate \n",
    "# decrease C by a little! (more regularization)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.01, class_weight='balanced') \n",
    "\n",
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that decreasing C below the default of C=1 to 0.01 increased the accuracy to about 0.68 without too much change in the confusion matrix values for the false negatives and true negatives (we really want to avoid a model that just predicts the majority class). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adjusting the parameters of the model several times to make the model more accurate, we chose the above parameters (the last cross validation output shown above) (penalty='l2', C=0.01, class_weight='balanced').\n",
    "\n",
    "We chose shuffle split cross validation for our cross validation data splitting technique with an 80/20 training/testing split. Because shuffle split does not divide the training data into distinct splits, but rather randomly shuffles the training data and samples again, we used 5 iterations because we wanted to ensure more data had the possiblity of being included in the cross validation splits. \n",
    "\n",
    "For the logistic regression cross validation output, we are getting accuracies consistently around 68%. This is not bad! However, accuracy is not always the best metric for model performance, especially with severly unbalanced data sets. \n",
    "\n",
    "This is why we also printed the confusion matrices for each model to achieve a more granular understanding of model performance. On average, it looks like this model has about 31,700 true positives (correct predictions), 14,500 false positives, 2,600 false negatives, and 5,300 true negatives. While these are not bad metrics, there is still some left for improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier with linear Support Vector Machine Model\n",
    "#### This code was changed to move the print line up to see the accuracies of each split for the model\n",
    "#### New code and output discussion was also added on changing the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.6834611979935085\n",
      "Confusion Matrix [[31687 14548]\n",
      " [ 2616  5373]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8537547949247566\n",
      "Confusion Matrix [[46186    15]\n",
      " [ 7915   108]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8562075833579227\n",
      "Confusion Matrix [[46342    15]\n",
      " [ 7782    85]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8565395396872234\n",
      "Confusion Matrix [[46353    18]\n",
      " [ 7761    92]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8545293596931248\n",
      "Confusion Matrix [[46236    13]\n",
      " [ 7875   100]]\n"
     ]
    }
   ],
   "source": [
    "# run linear support vector machines (SVM) to see how well a SVM model generalizes to the data\n",
    "\n",
    "# because of the large size of our data set, we will be using stochastic gradient descent (SGD)\n",
    "# because we are using SGD, we will not use cross-validation as SGD passes over the entire training set several \n",
    "# time to optimize it (we set our number of iterations to 4)\n",
    "\n",
    "# standardize the data before applying the SVM\n",
    "\n",
    "\n",
    "# use some compact notation for creating a linear SVM classifier with stochastic descent\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "regularize_const = 0.2\n",
    "iterations = 4\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', max_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv_object.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    print('SVM with SGD Accuracy:', acc) \n",
    "    print('Confusion Matrix', conf)\n",
    "  \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an alpha of 0.2, l2 penalty, and  l1_ratio=0.0 we achieved accuracies of 0.85. This is a much higher accuracy range than we were seeing with the logistic regression. It is worthy to note that there are very few true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8547137798760697\n",
      "Confusion Matrix [[46266    15]\n",
      " [ 7863    80]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8510253762171732\n",
      "Confusion Matrix [[46146     0]\n",
      " [ 8078     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8531646503393331\n",
      "Confusion Matrix [[46262     0]\n",
      " [ 7962     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8515417527294187\n",
      "Confusion Matrix [[46174     0]\n",
      " [ 8050     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8511729123635291\n",
      "Confusion Matrix [[46154     0]\n",
      " [ 8070     0]]\n"
     ]
    }
   ],
   "source": [
    "regularize_const = 0.2\n",
    "iterations = 4\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', max_iter=iterations, n_jobs=-1, penalty='l1')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv_object.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    print('SVM with SGD Accuracy:', acc) \n",
    "    print('Confusion Matrix', conf)\n",
    "  \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an alpha of 0.2, l1 penalty, and  l1_ratio=0.0 we achieved accuracies of about 0.85. Not a significant change in accuracy from changing the l1 vs l2 penalty. However, there are very few false postives or true negatives, so reverting back to l2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8535519327235173\n",
      "Confusion Matrix [[46283     0]\n",
      " [ 7941     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8520765712599587\n",
      "Confusion Matrix [[46203     0]\n",
      " [ 8021     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8566133077604013\n",
      "Confusion Matrix [[46449     0]\n",
      " [ 7775     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8563920035408675\n",
      "Confusion Matrix [[46437     0]\n",
      " [ 7787     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.856410445559162\n",
      "Confusion Matrix [[46438     0]\n",
      " [ 7786     0]]\n"
     ]
    }
   ],
   "source": [
    "regularize_const = 5\n",
    "iterations = 4\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', max_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv_object.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    print('SVM with SGD Accuracy:', acc) \n",
    "    print('Confusion Matrix', conf)\n",
    "  \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an alpha of 5, a much higher regularization multiplier, l2 penalty, and  l1_ratio=0.0 we achieved accuracies of about 0.85, but with very few false postives or true negatives. Reverting back to a smaller alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8544924756565359\n",
      "Confusion Matrix [[46334     0]\n",
      " [ 7890     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8555436706993214\n",
      "Confusion Matrix [[46301    72]\n",
      " [ 7761    90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8529433461197994\n",
      "Confusion Matrix [[46148   143]\n",
      " [ 7831   102]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8544002655650634\n",
      "Confusion Matrix [[46167   206]\n",
      " [ 7689   162]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8553961345529655\n",
      "Confusion Matrix [[46224   103]\n",
      " [ 7738   159]]\n"
     ]
    }
   ],
   "source": [
    "regularize_const = 0.001\n",
    "iterations = 4\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=1, learning_rate='optimal',\n",
    "        loss='hinge', max_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv_object.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    print('SVM with SGD Accuracy:', acc) \n",
    "    print('Confusion Matrix', conf)\n",
    "  \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an alpha of 0.001, a smaller regularization multiplier, l2 penalty, and  higher l1_ratio=1 we achieved accuracies of about 0.85, but with more false positives. Reverting back to a smaller l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8556912068456772\n",
      "Confusion Matrix [[46323    40]\n",
      " [ 7785    76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8531830923576276\n",
      "Confusion Matrix [[46108   179]\n",
      " [ 7782   155]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8526113897904987\n",
      "Confusion Matrix [[46126    62]\n",
      " [ 7930   106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8519659191501918\n",
      "Confusion Matrix [[46118    87]\n",
      " [ 7940    79]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8530171141929773\n",
      "Confusion Matrix [[46136    80]\n",
      " [ 7890   118]]\n"
     ]
    }
   ],
   "source": [
    "regularize_const = 0.001\n",
    "iterations = 4\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.001, learning_rate='optimal',\n",
    "        loss='hinge', max_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv_object.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    print('SVM with SGD Accuracy:', acc) \n",
    "    print('Confusion Matrix', conf)\n",
    "  \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an alpha of 0.001, l2 penalty, and  much smaller l1_ratio=0.001 we achieved accuracies of about 0.85, but with many more false positives. Reverting back to a l1_ratio=0. This makes sense since the l1_ratio=0 corresponds to an l2 penalty, which is what we are using!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8526113897904987\n",
      "Confusion Matrix [[46094   148]\n",
      " [ 7844   138]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8534781646503393\n",
      "Confusion Matrix [[46161   192]\n",
      " [ 7753   118]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8514311006196518\n",
      "Confusion Matrix [[46013   164]\n",
      " [ 7892   155]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8521318973148422\n",
      "Confusion Matrix [[46078   231]\n",
      " [ 7787   128]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with SGD Accuracy: 0.8518737090587194\n",
      "Confusion Matrix [[46050   229]\n",
      " [ 7803   142]]\n"
     ]
    }
   ],
   "source": [
    "regularize_const = 0.001\n",
    "iterations = 4\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', max_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv_object.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    print('SVM with SGD Accuracy:', acc) \n",
    "    print('Confusion Matrix', conf)\n",
    "  \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the final SVM with SGD ouput above, after changing different parameters, the model accuracy is about 85%. \n",
    "\n",
    "From the matrix: there are about 46,000 true positives, 70-300 false positives, 7,800 false negatives, and 100-200 true negatives. \n",
    "\n",
    "The time to run this SVM with SGD model runs faster than the logistic regression model. This is with 4 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF CHANGED CODE ON THE CREATE MODELS SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Advantages\n",
    "#### this commentary was changed as well, since we ended up getting a lower accuracy score for the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrices for the SVM with SGD and logistic regression using cross validation do not present drastically different results, but they are different. The biggest difference is when you weight the minority class more in logistic regression using class_weight=balance. \n",
    "\n",
    "The SVM with SGD model has about 46,000 true positives, 70-300 false positives (predicted a medal when there was none awarded), 7,800 false negatives (predicted no medal when a medal was actually awarded) and 100-200 true negatives (predicted no medal and no medal was awarded. The logistic regression model has about 31,700 true positives, 14,500 false positives, 2,600 false negatives, and 5,300 true negatives. Because the logsitic regression has a way to weight the unbalanaced classes, the logistic regression model does a better job at predicting true negatives. \n",
    "\n",
    "However, the accuracies of the SVM with SGD model is about 85% whereas the accuracy of the logistic regression model is 67%. \n",
    "From interpreting the confusion matrices as well as the accuracies, it looks like the logistic regression model may do a better job at actually correctly predicting the unbalanced classes and not just assigning the majority class all the time.\n",
    "\n",
    "However, there are other ways that one model could be preferred over another, such as time to compute, training time and efficiency.  \n",
    "\n",
    "Due to the size of our data set, we could not perform the cross validation for SVM in a reasonable time, so we had to use the SGD classifier to optimize the SVM model. The SVM with SGD works by iterating over the data multiple times. If you want to perform cross validation, the logistic regression model is much preferred to the SVM model because just using an SVM model with cross validation takes a LONG time (days) to run on our large data set.\n",
    "\n",
    "In terms of training time/running time/computing time, the time to run the 5 cross-validation splits with the logistic regression model was longer due to the time required for each iteration of cross validation. The SVM with SGD takes about half the time to run wih its iterations.  \n",
    "\n",
    "In conclusion, the time to run the two models is not drastically different, but the perforamnce of the models is different due to the unbalanced classes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGINNING OF CHANGED CODE ON THE INTERPRET FEATURE IMPORTANCE SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Insignificant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is a review of the coefficients from the logistic model in order to determine what, if any, features can be eliminated from the model in order to increase the interpretation of the model without sacrificing the model's core features (i.e., accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.111\n",
      "Model:                            OLS   Adj. R-squared:                  0.110\n",
      "Method:                 Least Squares   F-statistic:                     90.26\n",
      "Date:                Mon, 25 Feb 2019   Prob (F-statistic):               0.00\n",
      "Time:                        18:44:31   Log-Likelihood:                -69562.\n",
      "No. Observations:              216892   AIC:                         1.397e+05\n",
      "Df Residuals:                  216591   BIC:                         1.428e+05\n",
      "Df Model:                         300                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0017      0.000     11.683      0.000       0.001       0.002\n",
      "x2             0.0011      0.000      7.465      0.000       0.001       0.001\n",
      "x3             0.0006      0.000      5.882      0.000       0.000       0.001\n",
      "x4            -0.0008   3.01e-05    -25.234      0.000      -0.001      -0.001\n",
      "x5            -0.0415      0.002    -19.063      0.000      -0.046      -0.037\n",
      "x6             0.1718      0.035      4.900      0.000       0.103       0.241\n",
      "x7             0.1708      0.036      4.743      0.000       0.100       0.241\n",
      "x8             0.2319      0.047      4.977      0.000       0.141       0.323\n",
      "x9             0.2544      0.046      5.481      0.000       0.163       0.345\n",
      "x10            0.2569      0.022     11.572      0.000       0.213       0.300\n",
      "x11            0.3085      0.032      9.704      0.000       0.246       0.371\n",
      "x12            0.1610      0.028      5.783      0.000       0.106       0.216\n",
      "x13            0.2733      0.036      7.571      0.000       0.203       0.344\n",
      "x14            0.3967      0.042      9.517      0.000       0.315       0.478\n",
      "x15            0.2910      0.016     17.804      0.000       0.259       0.323\n",
      "x16            0.3145      0.029     10.710      0.000       0.257       0.372\n",
      "x17            0.2208      0.060      3.684      0.000       0.103       0.338\n",
      "x18            0.2229      0.065      3.443      0.001       0.096       0.350\n",
      "x19            0.3843      0.016     24.377      0.000       0.353       0.415\n",
      "x20            0.3316      0.016     21.105      0.000       0.301       0.362\n",
      "x21            0.3772      0.027     14.037      0.000       0.325       0.430\n",
      "x22            0.3640      0.025     14.797      0.000       0.316       0.412\n",
      "x23            0.2976      0.051      5.840      0.000       0.198       0.398\n",
      "x24            0.2688      0.030      9.035      0.000       0.210       0.327\n",
      "x25            0.3475      0.059      5.868      0.000       0.231       0.464\n",
      "x26            0.3292      0.016     20.857      0.000       0.298       0.360\n",
      "x27            0.2548      0.046      5.542      0.000       0.165       0.345\n",
      "x28            0.2364      0.030      7.981      0.000       0.178       0.294\n",
      "x29            0.2325      0.065      3.572      0.000       0.105       0.360\n",
      "x30            0.2842      0.036      7.860      0.000       0.213       0.355\n",
      "x31            0.2720      0.047      5.825      0.000       0.180       0.364\n",
      "x32            0.3334      0.018     18.669      0.000       0.298       0.368\n",
      "x33            0.2920      0.034      8.710      0.000       0.226       0.358\n",
      "x34            0.2777      0.034      8.131      0.000       0.211       0.345\n",
      "x35            0.2795      0.043      6.494      0.000       0.195       0.364\n",
      "x36            0.3288      0.016     20.027      0.000       0.297       0.361\n",
      "x37            0.3030      0.037      8.098      0.000       0.230       0.376\n",
      "x38            0.3053      0.127      2.410      0.016       0.057       0.554\n",
      "x39            0.3441      0.016     21.111      0.000       0.312       0.376\n",
      "x40            0.2573      0.059      4.352      0.000       0.141       0.373\n",
      "x41            0.2224      0.050      4.405      0.000       0.123       0.321\n",
      "x42            0.2564      0.050      5.091      0.000       0.158       0.355\n",
      "x43            0.3617      0.015     23.370      0.000       0.331       0.392\n",
      "x44            0.2517      0.043      5.821      0.000       0.167       0.336\n",
      "x45            0.2404      0.039      6.224      0.000       0.165       0.316\n",
      "x46            0.2752      0.061      4.525      0.000       0.156       0.394\n",
      "x47            0.2769      0.019     14.435      0.000       0.239       0.314\n",
      "x48            0.4276      0.016     26.308      0.000       0.396       0.459\n",
      "x49            0.2395      0.031      7.812      0.000       0.179       0.300\n",
      "x50            0.2738      0.026     10.457      0.000       0.222       0.325\n",
      "x51            0.2336      0.041      5.646      0.000       0.153       0.315\n",
      "x52            0.2352      0.060      3.924      0.000       0.118       0.353\n",
      "x53            0.2652      0.019     13.893      0.000       0.228       0.303\n",
      "x54            0.2877      0.082      3.501      0.000       0.127       0.449\n",
      "x55            0.2219      0.090      2.457      0.014       0.045       0.399\n",
      "x56            0.2501      0.028      8.946      0.000       0.195       0.305\n",
      "x57            0.3895      0.020     19.347      0.000       0.350       0.429\n",
      "x58            0.2262      0.106      2.133      0.033       0.018       0.434\n",
      "x59            0.3712      0.017     21.929      0.000       0.338       0.404\n",
      "x60            0.2729      0.029      9.454      0.000       0.216       0.329\n",
      "x61            0.3315      0.018     18.679      0.000       0.297       0.366\n",
      "x62            0.3691      0.016     23.136      0.000       0.338       0.400\n",
      "x63            0.2824      0.062      4.569      0.000       0.161       0.403\n",
      "x64            0.2851      0.090      3.158      0.002       0.108       0.462\n",
      "x65            0.2359      0.027      8.640      0.000       0.182       0.289\n",
      "x66            0.2652      0.028      9.605      0.000       0.211       0.319\n",
      "x67            0.2136      0.018     12.055      0.000       0.179       0.248\n",
      "x68            0.3408      0.060      5.671      0.000       0.223       0.459\n",
      "x69            0.2419      0.030      8.193      0.000       0.184       0.300\n",
      "x70            0.3133      0.016     19.535      0.000       0.282       0.345\n",
      "x71            0.3145      0.020     15.929      0.000       0.276       0.353\n",
      "x72            0.4183      0.024     17.089      0.000       0.370       0.466\n",
      "x73            0.5571      0.020     27.978      0.000       0.518       0.596\n",
      "x74            0.2667      0.028      9.374      0.000       0.211       0.322\n",
      "x75            0.4023      0.016     25.818      0.000       0.372       0.433\n",
      "x76            0.3631      0.015     24.036      0.000       0.333       0.393\n",
      "x77            0.4024      0.016     24.631      0.000       0.370       0.434\n",
      "x78            0.2697      0.078      3.464      0.001       0.117       0.422\n",
      "x79            0.2126      0.050      4.288      0.000       0.115       0.310\n",
      "x80            0.2865      0.054      5.342      0.000       0.181       0.392\n",
      "x81            0.3811      0.015     25.174      0.000       0.351       0.411\n",
      "x82            0.2555      0.082      3.108      0.002       0.094       0.417\n",
      "x83            0.6184      0.017     37.283      0.000       0.586       0.651\n",
      "x84            0.3614      0.027     13.440      0.000       0.309       0.414\n",
      "x85            0.2843      0.062      4.608      0.000       0.163       0.405\n",
      "x86            0.4471      0.015     28.965      0.000       0.417       0.477\n",
      "x87            0.2762      0.025     11.041      0.000       0.227       0.325\n",
      "x88            0.2895      0.016     17.926      0.000       0.258       0.321\n",
      "x89            0.3150      0.054      5.807      0.000       0.209       0.421\n",
      "x90            0.2459      0.024     10.412      0.000       0.200       0.292\n",
      "x91            0.2313      0.049      4.757      0.000       0.136       0.327\n",
      "x92            0.2426      0.039      6.244      0.000       0.166       0.319\n",
      "x93            0.2612      0.040      6.460      0.000       0.182       0.340\n",
      "x94            0.3081      0.039      7.876      0.000       0.231       0.385\n",
      "x95            0.2475      0.021     11.898      0.000       0.207       0.288\n",
      "x96            0.2150      0.031      6.939      0.000       0.154       0.276\n",
      "x97            0.3928      0.016     25.275      0.000       0.362       0.423\n",
      "x98            0.3414      0.024     14.260      0.000       0.294       0.388\n",
      "x99            0.3391      0.018     18.774      0.000       0.304       0.374\n",
      "x100           0.2803      0.042      6.692      0.000       0.198       0.362\n",
      "x101           0.2994      0.020     14.760      0.000       0.260       0.339\n",
      "x102           0.2530      0.018     13.855      0.000       0.217       0.289\n",
      "x103           0.1921      0.029      6.586      0.000       0.135       0.249\n",
      "x104           0.2658      0.021     12.588      0.000       0.224       0.307\n",
      "x105           0.2560      0.021     12.109      0.000       0.215       0.297\n",
      "x106           0.2497      0.026      9.453      0.000       0.198       0.302\n",
      "x107           0.3846      0.015     25.013      0.000       0.354       0.415\n",
      "x108           0.2651      0.055      4.833      0.000       0.158       0.373\n",
      "x109           0.4517      0.020     22.628      0.000       0.413       0.491\n",
      "x110           0.2467      0.045      5.444      0.000       0.158       0.336\n",
      "x111           0.3570      0.016     22.935      0.000       0.327       0.388\n",
      "x112           0.3067      0.018     16.667      0.000       0.271       0.343\n",
      "x113           0.3730      0.020     18.300      0.000       0.333       0.413\n",
      "x114           0.2624      0.029      9.035      0.000       0.205       0.319\n",
      "x115           0.2771      0.127      2.187      0.029       0.029       0.525\n",
      "x116           0.3719      0.016     22.826      0.000       0.340       0.404\n",
      "x117           0.4237      0.137      3.100      0.002       0.156       0.692\n",
      "x118           0.2934      0.029     10.232      0.000       0.237       0.350\n",
      "x119           0.2351      0.027      8.720      0.000       0.182       0.288\n",
      "x120           0.2798      0.052      5.331      0.000       0.177       0.383\n",
      "x121           0.2808      0.019     14.466      0.000       0.243       0.319\n",
      "x122           0.2390      0.042      5.678      0.000       0.156       0.321\n",
      "x123           0.2802      0.046      6.145      0.000       0.191       0.370\n",
      "x124           0.2686      0.073      3.698      0.000       0.126       0.411\n",
      "x125           0.2712      0.055      4.888      0.000       0.162       0.380\n",
      "x126           0.2747      0.026     10.551      0.000       0.224       0.326\n",
      "x127           0.3238      0.024     13.227      0.000       0.276       0.372\n",
      "x128           0.3330      0.021     15.545      0.000       0.291       0.375\n",
      "x129           0.2479      0.019     13.252      0.000       0.211       0.285\n",
      "x130           0.2587      0.037      6.914      0.000       0.185       0.332\n",
      "x131           0.1718      0.062      2.749      0.006       0.049       0.294\n",
      "x132           0.2748      0.021     13.112      0.000       0.234       0.316\n",
      "x133           0.2443      0.022     10.963      0.000       0.201       0.288\n",
      "x134           0.2698      0.041      6.637      0.000       0.190       0.350\n",
      "x135           0.2906      0.029      9.939      0.000       0.233       0.348\n",
      "x136           0.2992      0.055      5.455      0.000       0.192       0.407\n",
      "x137           0.2635      0.017     15.921      0.000       0.231       0.296\n",
      "x138           0.2955      0.022     13.421      0.000       0.252       0.339\n",
      "x139           0.2644      0.106      2.487      0.013       0.056       0.473\n",
      "x140           0.2907      0.045      6.456      0.000       0.202       0.379\n",
      "x141           0.2111      0.042      4.976      0.000       0.128       0.294\n",
      "x142           0.2313      0.038      6.118      0.000       0.157       0.305\n",
      "x143           0.2999      0.041      7.366      0.000       0.220       0.380\n",
      "x144           0.2634      0.030      8.697      0.000       0.204       0.323\n",
      "x145           0.2802      0.048      5.861      0.000       0.186       0.374\n",
      "x146           0.2590      0.035      7.495      0.000       0.191       0.327\n",
      "x147           0.2705      0.080      3.384      0.001       0.114       0.427\n",
      "x148           0.2241      0.040      5.671      0.000       0.147       0.302\n",
      "x149           0.3210      0.043      7.457      0.000       0.237       0.405\n",
      "x150           0.2686      0.236      1.140      0.254      -0.193       0.730\n",
      "x151           0.2174      0.038      5.786      0.000       0.144       0.291\n",
      "x152           0.3807      0.016     24.369      0.000       0.350       0.411\n",
      "x153           0.2632      0.041      6.472      0.000       0.184       0.343\n",
      "x154           0.2460      0.333      0.739      0.460      -0.406       0.898\n",
      "x155           0.3253      0.020     16.394      0.000       0.286       0.364\n",
      "x156           0.2973      0.056      5.295      0.000       0.187       0.407\n",
      "x157           0.4495      0.016     28.595      0.000       0.419       0.480\n",
      "x158           0.1980      0.106      1.861      0.063      -0.011       0.407\n",
      "x159           0.2927      0.017     17.131      0.000       0.259       0.326\n",
      "x160           0.2950      0.047      6.214      0.000       0.202       0.388\n",
      "x161           0.3897      0.022     17.979      0.000       0.347       0.432\n",
      "x162           0.2408      0.035      6.949      0.000       0.173       0.309\n",
      "x163           0.3610      0.035     10.255      0.000       0.292       0.430\n",
      "x164           0.2426      0.022     11.110      0.000       0.200       0.285\n",
      "x165           0.2412      0.021     11.760      0.000       0.201       0.281\n",
      "x166           0.2775      0.080      3.471      0.001       0.121       0.434\n",
      "x167           0.2526      0.074      3.404      0.001       0.107       0.398\n",
      "x168           0.2538      0.039      6.461      0.000       0.177       0.331\n",
      "x169           0.3220      0.016     20.484      0.000       0.291       0.353\n",
      "x170           0.2669      0.018     14.956      0.000       0.232       0.302\n",
      "x171           0.3550      0.020     17.720      0.000       0.316       0.394\n",
      "x172           0.2254      0.019     11.587      0.000       0.187       0.263\n",
      "x173           0.2614      0.031      8.431      0.000       0.201       0.322\n",
      "x174           0.2093      0.112      1.871      0.061      -0.010       0.428\n",
      "x175           0.2799      0.119      2.359      0.018       0.047       0.512\n",
      "x176           0.3789      0.016     23.553      0.000       0.347       0.410\n",
      "x177           0.2895      0.018     16.506      0.000       0.255       0.324\n",
      "x178           0.4743      0.016     29.083      0.000       0.442       0.506\n",
      "x179           0.2838      0.055      5.175      0.000       0.176       0.391\n",
      "x180           0.2453      0.041      6.036      0.000       0.166       0.325\n",
      "x181           0.2090      0.050      4.219      0.000       0.112       0.306\n",
      "x182           0.3850      0.026     14.754      0.000       0.334       0.436\n",
      "x183           0.2260      0.024      9.256      0.000       0.178       0.274\n",
      "x184           0.2517      0.039      6.538      0.000       0.176       0.327\n",
      "x185           0.2580      0.025     10.362      0.000       0.209       0.307\n",
      "x186           0.2859      0.058      4.961      0.000       0.173       0.399\n",
      "x187           0.2726      0.038      7.112      0.000       0.197       0.348\n",
      "x188           0.3132      0.019     16.403      0.000       0.276       0.351\n",
      "x189           0.2756      0.031      8.832      0.000       0.214       0.337\n",
      "x190           0.2646      0.076      3.482      0.000       0.116       0.414\n",
      "x191           0.2929      0.064      4.596      0.000       0.168       0.418\n",
      "x192           0.4238      0.025     17.112      0.000       0.375       0.472\n",
      "x193           0.2772      0.033      8.307      0.000       0.212       0.343\n",
      "x194           0.3047      0.193      1.581      0.114      -0.073       0.682\n",
      "x195           0.2915      0.097      2.996      0.003       0.101       0.482\n",
      "x196           0.2537      0.038      6.625      0.000       0.179       0.329\n",
      "x197           0.3533      0.016     22.599      0.000       0.323       0.384\n",
      "x198           0.3036      0.047      6.456      0.000       0.211       0.396\n",
      "x199           0.2915      0.019     15.016      0.000       0.253       0.330\n",
      "x200           0.4057      0.015     26.581      0.000       0.376       0.436\n",
      "x201           0.2740      0.046      5.915      0.000       0.183       0.365\n",
      "x202           0.2398      0.033      7.203      0.000       0.175       0.305\n",
      "x203           0.2639      0.034      7.856      0.000       0.198       0.330\n",
      "x204           0.3404      0.016     21.710      0.000       0.310       0.371\n",
      "x205           0.2349      0.054      4.333      0.000       0.129       0.341\n",
      "x206           0.2892      0.020     14.276      0.000       0.249       0.329\n",
      "x207           0.2751      0.047      5.835      0.000       0.183       0.367\n",
      "x208           0.2381      0.054      4.389      0.000       0.132       0.344\n",
      "x209           0.3026      0.127      2.389      0.017       0.054       0.551\n",
      "x210           0.2906      0.050      5.814      0.000       0.193       0.389\n",
      "x211           0.2808      0.019     14.905      0.000       0.244       0.318\n",
      "x212           0.3513      0.025     14.335      0.000       0.303       0.399\n",
      "x213           0.2145      0.022      9.831      0.000       0.172       0.257\n",
      "x214           0.2951      0.018     16.195      0.000       0.259       0.331\n",
      "x215           0.2855      0.127      2.253      0.024       0.037       0.534\n",
      "x216           0.2751      0.035      7.867      0.000       0.207       0.344\n",
      "x217           0.2334      0.038      6.159      0.000       0.159       0.308\n",
      "x218           0.2740      0.028      9.869      0.000       0.220       0.328\n",
      "x219           0.3395      0.017     19.704      0.000       0.306       0.373\n",
      "x220           0.3672      0.236      1.558      0.119      -0.095       0.829\n",
      "x221           0.6592      0.016     42.320      0.000       0.629       0.690\n",
      "x222           0.3010      0.021     14.011      0.000       0.259       0.343\n",
      "x223           0.5220      0.015     34.644      0.000       0.492       0.552\n",
      "x224           0.3042      0.023     13.293      0.000       0.259       0.349\n",
      "x225           0.2781      0.061      4.574      0.000       0.159       0.397\n",
      "x226           0.2434      0.020     12.367      0.000       0.205       0.282\n",
      "x227           0.2763      0.034      8.127      0.000       0.210       0.343\n",
      "x228           0.2873      0.062      4.652      0.000       0.166       0.408\n",
      "x229           0.2453      0.049      4.974      0.000       0.149       0.342\n",
      "x230           0.4630      0.090      5.138      0.000       0.286       0.640\n",
      "x231           0.2686      0.106      2.527      0.011       0.060       0.477\n",
      "x232           0.2743      0.062      4.440      0.000       0.153       0.395\n",
      "x233           0.2437      0.167      1.459      0.145      -0.084       0.571\n",
      "x234           0.3706      0.016     22.554      0.000       0.338       0.403\n",
      "x235           0.2377      0.032      7.481      0.000       0.175       0.300\n",
      "x236           0.2980      0.026     11.426      0.000       0.247       0.349\n",
      "x237           1.7040      0.337      5.053      0.000       1.043       2.365\n",
      "x238           0.9395      0.048     19.733      0.000       0.846       1.033\n",
      "x239           1.8098      0.085     21.389      0.000       1.644       1.976\n",
      "x240           0.8638      0.057     15.103      0.000       0.752       0.976\n",
      "x241           0.6725      0.056     11.979      0.000       0.562       0.783\n",
      "x242           0.8096      0.056     14.331      0.000       0.699       0.920\n",
      "x243           0.8489      0.058     14.669      0.000       0.735       0.962\n",
      "x244           1.0960      0.058     18.747      0.000       0.981       1.211\n",
      "x245           0.9372      0.057     16.441      0.000       0.825       1.049\n",
      "x246           1.7166      0.241      7.109      0.000       1.243       2.190\n",
      "x247           0.8254      0.059     13.886      0.000       0.709       0.942\n",
      "x248           0.9638      0.048     20.013      0.000       0.869       1.058\n",
      "x249           0.9917      0.048     20.685      0.000       0.898       1.086\n",
      "x250           0.9087      0.057     16.012      0.000       0.797       1.020\n",
      "x251           0.8940      0.057     15.683      0.000       0.782       1.006\n",
      "x252           1.6478      0.093     17.804      0.000       1.466       1.829\n",
      "x253           1.1155      0.102     10.936      0.000       0.916       1.315\n",
      "x254           0.9484      0.048     19.848      0.000       0.855       1.042\n",
      "x255           1.1789      0.051     23.049      0.000       1.079       1.279\n",
      "x256           0.8351      0.057     14.734      0.000       0.724       0.946\n",
      "x257           0.8476      0.057     14.905      0.000       0.736       0.959\n",
      "x258           0.8432      0.057     14.838      0.000       0.732       0.955\n",
      "x259           0.8513      0.056     15.084      0.000       0.741       0.962\n",
      "x260           1.0083      0.048     21.045      0.000       0.914       1.102\n",
      "x261           0.9702      0.057     17.114      0.000       0.859       1.081\n",
      "x262           0.9736      0.049     19.691      0.000       0.877       1.070\n",
      "x263           0.8123      0.061     13.341      0.000       0.693       0.932\n",
      "x264           0.7854      0.056     13.927      0.000       0.675       0.896\n",
      "x265           0.9882      0.057     17.267      0.000       0.876       1.100\n",
      "x266           1.0124      0.057     17.797      0.000       0.901       1.124\n",
      "x267           1.1272      0.048     23.592      0.000       1.034       1.221\n",
      "x268           0.8164      0.119      6.871      0.000       0.583       1.049\n",
      "x269           0.8966      0.057     15.719      0.000       0.785       1.008\n",
      "x270           1.6314      0.073     22.341      0.000       1.488       1.775\n",
      "x271           0.9681      0.049     19.924      0.000       0.873       1.063\n",
      "x272           1.3117      0.088     14.983      0.000       1.140       1.483\n",
      "x273           0.8127      0.057     14.162      0.000       0.700       0.925\n",
      "x274           1.1012      0.108     10.239      0.000       0.890       1.312\n",
      "x275           0.9902      0.049     20.244      0.000       0.894       1.086\n",
      "x276           1.3911      0.068     20.490      0.000       1.258       1.524\n",
      "x277           1.4837      0.111     13.391      0.000       1.267       1.701\n",
      "x278           0.9292      0.059     15.803      0.000       0.814       1.044\n",
      "x279           1.1385      0.200      5.698      0.000       0.747       1.530\n",
      "x280           0.9521      0.057     16.782      0.000       0.841       1.063\n",
      "x281           1.6285      0.063     25.992      0.000       1.506       1.751\n",
      "x282           0.9773      0.061     16.014      0.000       0.858       1.097\n",
      "x283           0.8923      0.057     15.710      0.000       0.781       1.004\n",
      "x284           0.8033      0.056     14.246      0.000       0.693       0.914\n",
      "x285           1.0638      0.049     21.790      0.000       0.968       1.159\n",
      "x286           1.0078      0.055     18.451      0.000       0.901       1.115\n",
      "x287           0.9618      0.048     19.853      0.000       0.867       1.057\n",
      "x288           0.9772      0.050     19.711      0.000       0.880       1.074\n",
      "x289           1.0782      0.059     18.193      0.000       0.962       1.194\n",
      "x290           0.9406      0.048     19.717      0.000       0.847       1.034\n",
      "x291           0.8456      0.057     14.902      0.000       0.734       0.957\n",
      "x292           0.9471      0.058     16.286      0.000       0.833       1.061\n",
      "x293           0.8268      0.058     14.359      0.000       0.714       0.940\n",
      "x294           1.0075      0.059     17.053      0.000       0.892       1.123\n",
      "x295           0.8224      0.057     14.434      0.000       0.711       0.934\n",
      "x296           0.9413      0.064     14.604      0.000       0.815       1.068\n",
      "x297           0.7983      0.060     13.395      0.000       0.682       0.915\n",
      "x298           1.3048      0.062     21.001      0.000       1.183       1.427\n",
      "x299           0.9637      0.057     16.821      0.000       0.851       1.076\n",
      "x300           0.9488      0.057     16.678      0.000       0.837       1.060\n",
      "x301           0.9072      0.057     16.018      0.000       0.796       1.018\n",
      "x302           0.9033      0.057     15.971      0.000       0.792       1.014\n",
      "==============================================================================\n",
      "Omnibus:                    61989.505   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           134325.156\n",
      "Skew:                           1.714   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.762   Cond. No.                     2.12e+19\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.91e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# eliminate variables that are not significant\n",
    "\n",
    "# because our dataset has so many attributes, we wil first run an OLS model on the data and look at the individual p-values \n",
    "# as a means of data reduction\n",
    "\n",
    "# attributes with a p-value greater than or equal to 0.05 are considered not signficant at the 95% confidence level\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "OLS_model=sm.OLS(y_train, X_train) # use the previously defined X_train and y_train\n",
    "result=OLS_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS model results above were pulled and considered with one key statistical variable in mind: p-value.  The team wanted to consider all of the coefficients available and determine if any were not statistically significant (p-value >= 5%).  Unfortunately (or fortunately for predictability purposes), very, very few features were deemed to be statistically insignificant.  That is, most of the features had a p-value less than 5%.  As a result, the potential of limiting features based on p-values was not utilized.\n",
    "\n",
    "As a result, we considered using a recursive feature elimination (RFE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      "  True False False False False False False False False False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False  True False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False  True False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False  True False False  True False False\n",
      " False False False False False False False False False  True False False\n",
      "  True False False  True False False False False False False False False\n",
      " False False  True False False False False False  True False False False\n",
      "  True  True  True False False False False False False False False  True\n",
      " False False False  True  True False False False False False False False\n",
      "  True False False False False False False False False  True  True  True\n",
      " False False]\n",
      "[253 263 271 264 171  15  94 152 158  45 123  32 115  75  57 203 184 200\n",
      "  23  72  78  91 188  85 260  71 159  77 183 124 153 197 243 109 176 143\n",
      " 156 251 142 196 155 169  37 138 128 208  44   9  98 129 131 192   1 231\n",
      " 239  74  69 249  40  87 202  26 207 238  81  73   1 235  79 166 146  35\n",
      "   1 139  16  25  18 234 165 186  19 229   1 201 206   3 100 160 250  11\n",
      " 137 121 154 255   1  67  20 213 145 245 195   1  55   7   1  56  21 210\n",
      "  13 161  70  84  36  90 248  62 256 120  54 185  58 134 172 227 162  63\n",
      " 164 187   1 118 177  51  12 148 122 199   1  93 242 182 125 107 257  99\n",
      " 173 105 224 112 204 265 103  22 150 273 110 232   4 233 270 168  65 130\n",
      " 190  42   5 241 215 126 144   1 225   1 132 240 246  24 219   1 193 141\n",
      " 147  83  28 119  76 212 136  86  97 221 222  61 104 267 237 133  39 194\n",
      "  52  17 163 113 116  68 209  53 217 167 254 198   8 157   6 117 259 108\n",
      " 127 111 226 272   1 220   1 174 214   1 135 211 191 178 258 216 261  41\n",
      "  89 179 247   1  59 106   1  14  95   1  60 218 101  48 266 175 268  82\n",
      " 205  43   1  34  46  96 102 236   1 170 114  10   1   1   1 262 228   2\n",
      " 149 140  30 189 269   1 151  88 244   1   1  64 252  27  66 223  50  92\n",
      "   1  49  31  80  29  38  47 230  33   1   1   1 180 181]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE  \n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y):     \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "rfe = RFE(lr_clf, 30)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFE parameters set the sought features to 30.  The nature of the RFE is that feature is removed and the model is run, and so one (with an additional feature being removed each time) until the paramterized number of features is remaining.  Given the sheer number of features considered (300+) and the goal of getting a logistic model that is also interpretable, the RFE was used to eliminate features.  What follows below is an updated model with the RFE selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col in['IsMedal','NOC_COL','NOC_EGY','NOC_EUN','NOC_GDR','NOC_HKG','NOC_IRL','NOC_ISR','NOC_LUX','NOC_MEX','NOC_POR','NOC_PUR','NOC_RUS','NOC_URS','NOC_USA','NOC_VEN','Sport_Alpine Skiing','Sport_Art Competitions','Sport_Baseball','Sport_Curling','Sport_Football','Sport_Handball','Sport_Hockey','Sport_Ice Hockey','Sport_Polo','Sport_Rowing','Sport_Rugby','Sport_Softball','Sport_Tug-Of-War','Sport_Volleyball','Sport_Water Polo']]\n",
    "df_final = df[cols]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsMedal</th>\n",
       "      <th>NOC_COL</th>\n",
       "      <th>NOC_EGY</th>\n",
       "      <th>NOC_EUN</th>\n",
       "      <th>NOC_GDR</th>\n",
       "      <th>NOC_HKG</th>\n",
       "      <th>NOC_IRL</th>\n",
       "      <th>NOC_ISR</th>\n",
       "      <th>NOC_LUX</th>\n",
       "      <th>NOC_MEX</th>\n",
       "      <th>...</th>\n",
       "      <th>Sport_Handball</th>\n",
       "      <th>Sport_Hockey</th>\n",
       "      <th>Sport_Ice Hockey</th>\n",
       "      <th>Sport_Polo</th>\n",
       "      <th>Sport_Rowing</th>\n",
       "      <th>Sport_Rugby</th>\n",
       "      <th>Sport_Softball</th>\n",
       "      <th>Sport_Tug-Of-War</th>\n",
       "      <th>Sport_Volleyball</th>\n",
       "      <th>Sport_Water Polo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.146738</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.039079</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.014186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.353845</td>\n",
       "      <td>0.062669</td>\n",
       "      <td>0.077116</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.098290</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.102518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115479</td>\n",
       "      <td>0.139933</td>\n",
       "      <td>0.141180</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.193784</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>0.111346</td>\n",
       "      <td>0.118257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             IsMedal        NOC_COL        NOC_EGY        NOC_EUN  \\\n",
       "count  271116.000000  271116.000000  271116.000000  271116.000000   \n",
       "mean        0.146738       0.003943       0.005983       0.003187   \n",
       "std         0.353845       0.062669       0.077116       0.056362   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             NOC_GDR        NOC_HKG        NOC_IRL        NOC_ISR  \\\n",
       "count  271116.000000  271116.000000  271116.000000  271116.000000   \n",
       "mean        0.009756       0.002527       0.004887       0.002453   \n",
       "std         0.098290       0.050202       0.069738       0.049465   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             NOC_LUX        NOC_MEX        ...         Sport_Handball  \\\n",
       "count  271116.000000  271116.000000        ...          271116.000000   \n",
       "mean        0.003674       0.010623        ...               0.013518   \n",
       "std         0.060500       0.102518        ...               0.115479   \n",
       "min         0.000000       0.000000        ...               0.000000   \n",
       "25%         0.000000       0.000000        ...               0.000000   \n",
       "50%         0.000000       0.000000        ...               0.000000   \n",
       "75%         0.000000       0.000000        ...               0.000000   \n",
       "max         1.000000       1.000000        ...               1.000000   \n",
       "\n",
       "        Sport_Hockey  Sport_Ice Hockey     Sport_Polo   Sport_Rowing  \\\n",
       "count  271116.000000     271116.000000  271116.000000  271116.000000   \n",
       "mean        0.019980          0.020346       0.000350       0.039079   \n",
       "std         0.139933          0.141180       0.018716       0.193784   \n",
       "min         0.000000          0.000000       0.000000       0.000000   \n",
       "25%         0.000000          0.000000       0.000000       0.000000   \n",
       "50%         0.000000          0.000000       0.000000       0.000000   \n",
       "75%         0.000000          0.000000       0.000000       0.000000   \n",
       "max         1.000000          1.000000       1.000000       1.000000   \n",
       "\n",
       "         Sport_Rugby  Sport_Softball  Sport_Tug-Of-War  Sport_Volleyball  \\\n",
       "count  271116.000000   271116.000000     271116.000000     271116.000000   \n",
       "mean        0.000598        0.001763          0.000627          0.012556   \n",
       "std         0.024437        0.041952          0.025033          0.111346   \n",
       "min         0.000000        0.000000          0.000000          0.000000   \n",
       "25%         0.000000        0.000000          0.000000          0.000000   \n",
       "50%         0.000000        0.000000          0.000000          0.000000   \n",
       "75%         0.000000        0.000000          0.000000          0.000000   \n",
       "max         1.000000        1.000000          1.000000          1.000000   \n",
       "\n",
       "       Sport_Water Polo  \n",
       "count     271116.000000  \n",
       "mean           0.014186  \n",
       "std            0.118257  \n",
       "min            0.000000  \n",
       "25%            0.000000  \n",
       "50%            0.000000  \n",
       "75%            0.000000  \n",
       "max            1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the new data\n",
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=5, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# first we must create new X and y arrays (X2, y2)\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X2 and y2 data as follows:\n",
    "if 'IsMedal' in df_final:\n",
    "    y2 = df_final['IsMedal'].values # get the labels we want  \n",
    "    X2 = df_final.loc[:, df_final.columns != 'IsMedal'].values # use everything else to predict!\n",
    "\n",
    "# X2 and y2 are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "# have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "# create a test size that is 20% of the data (80/20 split)\n",
    "num_cv_iterations = 5  \n",
    "num_instances = len(y2)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size  = 0.2)\n",
    "#view the object                          \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create new training and testing sets with the reduced data\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X2,y2): \n",
    "    X_train = X2[train_indices]\n",
    "    y_train = y2[train_indices]\n",
    "    \n",
    "    X_test = X2[test_indices]\n",
    "    y_test = y2[test_indices]         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\brndn\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.751567571555031\n",
      "[[36916  9511]\n",
      " [ 3960  3837]]\n",
      "NOC_LUX has weight of -0.19084940570374145\n",
      "NOC_HKG has weight of -0.1742439325590232\n",
      "NOC_EGY has weight of -0.17034519782902055\n",
      "Sport_Alpine Skiing has weight of -0.16586842442883132\n",
      "NOC_PUR has weight of -0.1520570833252802\n",
      "NOC_MEX has weight of -0.13733389477184038\n",
      "Sport_Art Competitions has weight of -0.13084973831817473\n",
      "NOC_POR has weight of -0.12768141208851305\n",
      "NOC_VEN has weight of -0.12345685024430031\n",
      "NOC_IRL has weight of -0.12143275099058513\n",
      "NOC_COL has weight of -0.11315337985281454\n",
      "NOC_ISR has weight of -0.10759295551169715\n",
      "Sport_Curling has weight of 0.055152371069320714\n",
      "Sport_Softball has weight of 0.059218389440451616\n",
      "Sport_Polo has weight of 0.05954812330773339\n",
      "NOC_EUN has weight of 0.06710092551230248\n",
      "Sport_Tug-Of-War has weight of 0.07437356212386259\n",
      "Sport_Baseball has weight of 0.08483095635589441\n",
      "Sport_Volleyball has weight of 0.10022588656803788\n",
      "NOC_RUS has weight of 0.10437005197302295\n",
      "Sport_Water Polo has weight of 0.11865775571243929\n",
      "Sport_Handball has weight of 0.1259641431460834\n",
      "Sport_Ice Hockey has weight of 0.1268609094313459\n",
      "Sport_Football has weight of 0.1355248677575805\n",
      "NOC_GDR has weight of 0.14338705017987985\n",
      "Sport_Hockey has weight of 0.1568989122009265\n",
      "Sport_Rugby has weight of 0.17489911831525637\n",
      "Sport_Rowing has weight of 0.18662552515309067\n",
      "NOC_URS has weight of 0.23985367222670875\n",
      "NOC_USA has weight of 0.2838454801931273\n"
     ]
    }
   ],
   "source": [
    "# now that we have removed insignificant attributes, we can run the logistic model and interpret the coefficients (scale them first \n",
    "# in order to intrepret them correctly)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "# X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.01, class_weight='balanced') # get object\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and print them\n",
    "zip_vars = zip(lr_clf.coef_.T,df_final.loc[:, df_final.columns != 'IsMedal']) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new logistic regression model has an accuracy of 75%. \n",
    "\n",
    "The model has about approximately 37,000 true positives, 9,500 false positives, 3,900 false negatives, and 3,800 true negatives. These model metrics are very similar to the previous cross validation logistic regresssion metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGINNING OF CHANGED CODE ON THE INTERPRET FEATURE IMPORTANCE SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As has been discussed in the prior lab as well as throughout this report, the dataset being considered and analyzed is intrinsically difficult with respect to interpretability as part of a logistics regression model.  Put another way, the original data set contained a handful of variables, such as country, sport, or year, and many of these variables contained hundreds of classes (i.e., country variable has a different class for each country that competes in the games).  Building a logistic regression model requires assigning a numerical, binary aspect to each class for each variable in order to understand that particular class and its ability to predict a given output.  \n",
    "\n",
    "What does this all mean?  Before we began eliminating features and after we structured the data to build a model, we established 302 prediction features.  302!  Writing that model alone and asking a human mind to appreciate and analyze all of the coefficients is clearly too much.  \n",
    "\n",
    "After performing the RFE, the features that remained as a result of the RFE were all class levels of the core variables related to country or sport.  Country features provided the highest predictive coefficients (US ~ 0.28, URS ~ 0.24, LUX ~ -0.19, HKG ~ - 0.17, etc.).  Sports such as rowing (~0.18), rugby (~0.17), hockey (~0.16), football (~0.14), ice hockey (~0.13), handball (~0.13), water polo (~0.12), volleyball (~0.10), baseball (~0.08), tug-of-war (~ 0.07), polo (~ 0.06), softball (~ 0.06), and curling (~ 0.06) were the only sport related features that had positive coefficients (i.e., you were more likely to win a medal if you played in that sport).  These sports all shared another feature; they were all team sports.  Whereas sports such as alpine skiing (~ -0.17) and sport-art competitions (~ -0.13) are individual sports.  This seems to make sense: if you were part of team (and the winning team is awarded a metal to each participant), your odds of winning a medal would seem to increase if your sport had less teams participating (such as rugby or polo) and greater numbers of team members (such as ice hockey).\n",
    "\n",
    "The country results are interesting in that there seems to be clear dichotomy between high performing countries (as mentioned previously this would include USA, URS, and RUS ~ 0.10) and low performing countries (LUX, HKG, EGY ~ -0.17, PUR ~ -0.15, or MEX ~ -0.14).  This is somewhat to be expected again.  USSR (including Russia since that political change) and the USA often competed for metal supremacy; merely making those teams was in itself a difficult competition so it stands to reason that once you made the team...your chances of medalling were high.  Likewise, Hong Kong or Luxembourg are not necessarily populous countries known for fostering athletic talent.  Thus, even if you made it to the Olympics, if you were part of those country contingents you are competing against athletes that went through the grueling selection process in more competitive countries.  \n",
    "\n",
    "As has been discussed previously, a key consideration going forward is whether RFE is worthwhile as a step.  While eliminating so many features makes interpreting the model easier (for a human user), it also makes the model potentially less useful.  For example, if the athlete was competing in track and field and came from Brazil, the model would have difficulty providing a useful prediction as those features are not even represented!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOC_LUX</td>\n",
       "      <td>-0.190849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOC_HKG</td>\n",
       "      <td>-0.174244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOC_EGY</td>\n",
       "      <td>-0.170345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sport_Alpine Skiing</td>\n",
       "      <td>-0.165868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOC_PUR</td>\n",
       "      <td>-0.152057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOC_MEX</td>\n",
       "      <td>-0.137334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sport_Art Competitions</td>\n",
       "      <td>-0.130850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOC_POR</td>\n",
       "      <td>-0.127681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOC_VEN</td>\n",
       "      <td>-0.123457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOC_IRL</td>\n",
       "      <td>-0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NOC_COL</td>\n",
       "      <td>-0.113153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NOC_ISR</td>\n",
       "      <td>-0.107593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sport_Curling</td>\n",
       "      <td>0.055152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sport_Softball</td>\n",
       "      <td>0.059218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sport_Polo</td>\n",
       "      <td>0.059548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NOC_EUN</td>\n",
       "      <td>0.067101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sport_Tug-Of-War</td>\n",
       "      <td>0.074374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sport_Baseball</td>\n",
       "      <td>0.084831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sport_Volleyball</td>\n",
       "      <td>0.100226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NOC_RUS</td>\n",
       "      <td>0.104370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sport_Water Polo</td>\n",
       "      <td>0.118658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sport_Handball</td>\n",
       "      <td>0.125964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sport_Ice Hockey</td>\n",
       "      <td>0.126861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sport_Football</td>\n",
       "      <td>0.135525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NOC_GDR</td>\n",
       "      <td>0.143387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sport_Hockey</td>\n",
       "      <td>0.156899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sport_Rugby</td>\n",
       "      <td>0.174899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sport_Rowing</td>\n",
       "      <td>0.186626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NOC_URS</td>\n",
       "      <td>0.239854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NOC_USA</td>\n",
       "      <td>0.283845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       col       val\n",
       "0                  NOC_LUX -0.190849\n",
       "1                  NOC_HKG -0.174244\n",
       "2                  NOC_EGY -0.170345\n",
       "3      Sport_Alpine Skiing -0.165868\n",
       "4                  NOC_PUR -0.152057\n",
       "5                  NOC_MEX -0.137334\n",
       "6   Sport_Art Competitions -0.130850\n",
       "7                  NOC_POR -0.127681\n",
       "8                  NOC_VEN -0.123457\n",
       "9                  NOC_IRL -0.121433\n",
       "10                 NOC_COL -0.113153\n",
       "11                 NOC_ISR -0.107593\n",
       "12           Sport_Curling  0.055152\n",
       "13          Sport_Softball  0.059218\n",
       "14              Sport_Polo  0.059548\n",
       "15                 NOC_EUN  0.067101\n",
       "16        Sport_Tug-Of-War  0.074374\n",
       "17          Sport_Baseball  0.084831\n",
       "18        Sport_Volleyball  0.100226\n",
       "19                 NOC_RUS  0.104370\n",
       "20        Sport_Water Polo  0.118658\n",
       "21          Sport_Handball  0.125964\n",
       "22        Sport_Ice Hockey  0.126861\n",
       "23          Sport_Football  0.135525\n",
       "24                 NOC_GDR  0.143387\n",
       "25            Sport_Hockey  0.156899\n",
       "26             Sport_Rugby  0.174899\n",
       "27            Sport_Rowing  0.186626\n",
       "28                 NOC_URS  0.239854\n",
       "29                 NOC_USA  0.283845"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe using zip array for plotting\n",
    "plt_df = pd.DataFrame(columns=['col','val'])\n",
    "i = 0\n",
    "for coef, name in zip_vars:\n",
    "   plt_df.loc[i] = [name,coef[0]]\n",
    "   i+=1\n",
    "\n",
    "plt_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1084fc8e6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's graph the coefficients and make it easier to see all the values at once\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "#plt.bar(plt_df['col'],plt_df['val'])\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=plt_df['col'])\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF CHANGED CODE ON THE INTERPRET FEATURE IMPORTANCE SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scl_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cfa4906e3297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscl_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# apply to training\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscl_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scl_obj' is not defined"
     ]
    }
   ],
   "source": [
    "# train the model with just SVM.. but use a VERY small sample of the model so it runs in a timely manner\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# randomly sample a subset of the df for the SVM model\n",
    "\n",
    "df_svm = df.sample(frac=0.05)\n",
    "\n",
    "# we want to predict the X3 and y3 data as follows:\n",
    "if 'IsMedal' in df_svm:\n",
    "    y3 = df_svm['IsMedal'].values # get the labels we want  \n",
    "    X3 = df_svm.loc[:, df_svm.columns != 'IsMedal'].values # use everything else to predict!\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X3,y3): \n",
    "    X_train = X3[train_indices]\n",
    "    y_train = y3[train_indices]\n",
    "    \n",
    "    X_test = X3[test_indices]\n",
    "    y_test = y3[test_indices]\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the SVM on just 5% of the data computed very quickly (in contrast to the days it took to run SVM on the 80% training data). \n",
    "\n",
    "The accuracy is not bad at 85%. It is about the same accuracy of the other models. It is interesting to note that there are 0 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3121, 30)\n",
      "(3121,)\n",
      "[1578 1543]\n"
     ]
    }
   ],
   "source": [
    "# look at the support vectors from the SVM model\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3121 entries, 224049 to 218590\n",
      "Data columns (total 31 columns):\n",
      "IsMedal                   3121 non-null int32\n",
      "NOC_COL                   3121 non-null uint8\n",
      "NOC_EGY                   3121 non-null uint8\n",
      "NOC_EUN                   3121 non-null uint8\n",
      "NOC_GDR                   3121 non-null uint8\n",
      "NOC_HKG                   3121 non-null uint8\n",
      "NOC_IRL                   3121 non-null uint8\n",
      "NOC_ISR                   3121 non-null uint8\n",
      "NOC_LUX                   3121 non-null uint8\n",
      "NOC_MEX                   3121 non-null uint8\n",
      "NOC_POR                   3121 non-null uint8\n",
      "NOC_PUR                   3121 non-null uint8\n",
      "NOC_RUS                   3121 non-null uint8\n",
      "NOC_URS                   3121 non-null uint8\n",
      "NOC_USA                   3121 non-null uint8\n",
      "NOC_VEN                   3121 non-null uint8\n",
      "Sport_Alpine Skiing       3121 non-null uint8\n",
      "Sport_Art Competitions    3121 non-null uint8\n",
      "Sport_Baseball            3121 non-null uint8\n",
      "Sport_Curling             3121 non-null uint8\n",
      "Sport_Football            3121 non-null uint8\n",
      "Sport_Handball            3121 non-null uint8\n",
      "Sport_Hockey              3121 non-null uint8\n",
      "Sport_Ice Hockey          3121 non-null uint8\n",
      "Sport_Polo                3121 non-null uint8\n",
      "Sport_Rowing              3121 non-null uint8\n",
      "Sport_Rugby               3121 non-null uint8\n",
      "Sport_Softball            3121 non-null uint8\n",
      "Sport_Tug-Of-War          3121 non-null uint8\n",
      "Sport_Volleyball          3121 non-null uint8\n",
      "Sport_Water Polo          3121 non-null uint8\n",
      "dtypes: int32(1), uint8(30)\n",
      "memory usage: 128.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
    "\n",
    "# now let's look at the support for the vectors and see if we they are indicative of anything\n",
    "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
    "\n",
    "# make a dataframe of the training data\n",
    "df_tested_on = df_svm.iloc[train_indices] # saved from above, the indices chosen for training\n",
    "# now get the support vectors from the trained model\n",
    "df_support = df_tested_on.iloc[svm_clf.support_,:]\n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Support Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b16f056adf5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# plot support vector stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_grouped_support\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Medal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'None'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' (Instances chosen as Support Vectors)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Column not found: {key}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: Age'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10851b0c7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "from pandas.tools.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['IsMedal'])\n",
    "df_grouped = df_svm.groupby(['IsMedal'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['Age','Height','IsMale','Weight']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['Medal','None'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['Medal','None'])\n",
    "    plt.title(v+' (Original)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector analysis shows the original statistics of these variables as well as the statistics of the support vectors.  \n",
    "We chose just to look at a few interesting variables that were chosen as support vectors: Age, Height, IsMale, and Weight.\n",
    "\n",
    "The separation in distributions (the distance between the orange and blue lines) between None and Medal for all of the above vairiables is greater that the separation in None and Medal distributions for the support vectors. Support vectors are usually the instances in the data that are close to the class boundary (close to the None and Medal class boundary) which is why the distribution separation is not as large. Support vectors are also the instances that are frequenlty missclassified (beacause they are on the edge of the classificaiton boundary).\n",
    "\n",
    "From looking at just these four support vector distribution separations, it looks like there are many instances that lie on the Medal and None classification boundary for Weight, Height, and Age. It is harder to correctly classify with these attributes. We could have already guessed this with our previous exploratory data analysis: the distributions of Age, Height, and Weight were very tight and similar for the Olympic athletes who both medaled and didn't medal. \n",
    "\n",
    "The IsMale attribute has a greater separation between the classes, meaning there are less of the IsMale instances lying on the classification boundary. This further indicates that IsMale is a good predictor for the Medal or None because there is a large distribution separation in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
